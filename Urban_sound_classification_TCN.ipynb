{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Urban_sound_classification_TCN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3zjNJmk-Vya4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f6d0b153-f95e-4f77-89b1-0e2885cfa9c2"
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import rnn, rnn_cell\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oxj4VMHHWQfu",
        "colab_type": "code",
        "outputId": "6e380240-2db9-43d3-910a-e9a07b064663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"drive/My Drive/Dataset\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Test  test.csv\tTrain  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GibR5XZDWfH2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train  = pd.read_csv('drive/My Drive/Dataset/train.csv')\n",
        "data_dir = 'drive/My Drive/Dataset'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bAJ9NkL4dhxe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parser(row):\n",
        "   # function to load files and extract features\n",
        "  file_name = os.path.join(os.path.abspath(data_dir), 'Train', str(row.ID) + '.wav')\n",
        "\n",
        "   # handle exception to check if there isn't a file which is corrupted\n",
        "  try:\n",
        "      # here kaiser_fast is a technique used for faster extraction\n",
        "      X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "      # we extract mfcc feature from data\n",
        "      mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "  except Exception as e:\n",
        "      print(\"Error encountered while parsing file: \", file)\n",
        "      return None, None\n",
        " \n",
        "  feature = mfccs\n",
        "  label = row.Class\n",
        " \n",
        "  return [feature, label]\n",
        "\n",
        "temp = train.apply(parser, axis=1)\n",
        "temp.columns = ['feature', 'label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S7MEK2OldmXw",
        "colab_type": "code",
        "outputId": "c8e3a46d-396c-468e-b73c-e2474b007653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "train_x = np.array(temp.feature.tolist())\n",
        "train_y = np.array(temp.label.tolist())\n",
        "\n",
        "lb = LabelEncoder()\n",
        "\n",
        "train_y = tf.keras.utils.to_categorical(lb.fit_transform(train_y))\n",
        "print(type(train_y))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hSrqoWr9cSYS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d9IYv3TBfMlJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x75jmmbFfP6c",
        "colab_type": "code",
        "outputId": "9a50e72f-24f5-4065-e107-9e5883b67fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from numpy import newaxis\n",
        "train_x.shape\n",
        "train_x = train_x[:,:,newaxis]\n",
        "print(train_x.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5435, 40, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KrqTi9_RfTV9",
        "colab_type": "code",
        "outputId": "5a93c4fc-1d7f-47f6-98ae-0d36fd920fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "train_y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "0W_iuehxstaY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CausalConv1D(tf.layers.Conv1D):\n",
        "    def __init__(self, filters,\n",
        "               kernel_size,\n",
        "               strides=1,\n",
        "               dilation_rate=1,\n",
        "               activation=None,\n",
        "               use_bias=True,\n",
        "               kernel_initializer=None,\n",
        "               bias_initializer=tf.zeros_initializer(),\n",
        "               kernel_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               trainable=True,\n",
        "               name=None,\n",
        "               **kwargs):\n",
        "        super(CausalConv1D, self).__init__(\n",
        "            filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            strides=strides,\n",
        "            padding='valid',\n",
        "            data_format='channels_last',\n",
        "            dilation_rate=dilation_rate,\n",
        "            activation=activation,\n",
        "            use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer,\n",
        "            bias_initializer=bias_initializer,\n",
        "            kernel_regularizer=kernel_regularizer,\n",
        "            bias_regularizer=bias_regularizer,\n",
        "            activity_regularizer=activity_regularizer,\n",
        "            kernel_constraint=kernel_constraint,\n",
        "            bias_constraint=bias_constraint,\n",
        "            trainable=trainable,\n",
        "            name=name, **kwargs\n",
        "        )\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        padding = (self.kernel_size[0] - 1) * self.dilation_rate[0]\n",
        "        if self.data_format == 'channels_first':\n",
        "            inputs = tf.pad(inputs, tf.constant([[0, 0], [0, 0], [padding, 0]], dtype=tf.int32))\n",
        "        else:\n",
        "            inputs = tf.pad(inputs, tf.constant([(0, 0,), (padding, 0), (0, 0)]))\n",
        "        return super(CausalConv1D, self).call(inputs), inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fedqzXb5t01H",
        "colab_type": "code",
        "outputId": "71f531df-3a28-4012-c7aa-98398cc6bd1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Graph().as_default() as g:\n",
        "    x = tf.random_normal((32, 10, 4)) # (batch_size, length, channel)\n",
        "    with tf.variable_scope(\"tcn\"):\n",
        "        conv = CausalConv1D(8, 3, activation=tf.nn.relu)\n",
        "    output = conv(x)\n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "with tf.Session(graph=g) as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    res, inputs = sess.run(output)\n",
        "    print(inputs.shape)\n",
        "    print(inputs[0, :, 0])\n",
        "    print(res.shape)    \n",
        "    print(res[0, :, 0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 12, 4)\n",
            "[ 0.          0.          0.19434792  0.62958175  1.5533562   0.9575418\n",
            " -0.08206888  0.03701568  0.7041562   1.2063874  -0.65986335  0.10659102]\n",
            "(32, 10, 8)\n",
            "[0.        0.        0.        0.        0.0213389 0.        0.\n",
            " 0.        0.        0.       ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EJvrq3KEuHs9",
        "colab_type": "code",
        "outputId": "b8e3286d-e5a6-47fc-eac6-b2b9285ecf23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Graph().as_default() as g:\n",
        "    x = tf.expand_dims(\n",
        "        tf.expand_dims(tf.constant([1, 0, 0, 1, 0, 0, 1], dtype=tf.float32), axis=0),\n",
        "        axis=-1) # (batch_size, length, channel)\n",
        "    with tf.variable_scope(\"tcn\"):\n",
        "        conv = CausalConv1D(8, 2, dilation_rate=2, activation=None)\n",
        "    output = conv(x)\n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "with tf.Session(graph=g) as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    res, inputs = sess.run(output)\n",
        "    print(inputs.shape)\n",
        "    print(inputs[0, :, 0])\n",
        "    print(res.shape)    \n",
        "    print(res[0, :, 0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 9, 1)\n",
            "[0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
            "(1, 7, 8)\n",
            "[-0.2616848  0.         0.3173225 -0.2616848  0.         0.3173225\n",
            " -0.2616848]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xSA6uv_0uKEp",
        "colab_type": "code",
        "outputId": "e82c634a-82b2-40d5-ca2f-2a020a1ed0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Graph().as_default() as g:\n",
        "    x = tf.random_normal((32, 4, 10)) # (batch_size, channel, length)\n",
        "    dropout = tf.layers.Dropout(0.5, noise_shape=[x.shape[0], x.shape[1], tf.constant(1)])\n",
        "    output = dropout(x, training=True)\n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "with tf.Session(graph=g) as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    res = sess.run(output)\n",
        "    print(res.shape)   \n",
        "    print(res[0, :, :])\n",
        "    print(res[1, :, :])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 4, 10)\n",
            "[[-2.3285773   0.08641841 -1.4585888  -0.653349   -0.06835803 -0.9478375\n",
            "   1.4381355  -3.091065   -1.319882   -1.5865655 ]\n",
            " [-0.         -0.          0.         -0.          0.         -0.\n",
            "  -0.          0.         -0.          0.        ]\n",
            " [-0.          0.          0.         -0.          0.         -0.\n",
            "   0.         -0.          0.         -0.        ]\n",
            " [-1.0714962   1.1951921   0.99483836  1.7352117  -2.016487   -1.8198144\n",
            "   2.097631    0.7876429   0.05295105  2.3481727 ]]\n",
            "[[-0.40814415 -1.2866764  -0.5079775  -0.977586   -0.08755136 -1.3722992\n",
            "  -3.667378    0.14989467  2.2631004   1.4908382 ]\n",
            " [-3.100421    1.6499041   1.2775149  -0.43227136  0.7758265   1.6978185\n",
            "   0.9040202  -1.8233161  -2.1887565   1.0640903 ]\n",
            " [-0.         -0.         -0.         -0.          0.         -0.\n",
            "  -0.         -0.          0.          0.        ]\n",
            " [ 0.7119539   0.68701047 -0.9982313  -0.86383283  0.87027013  0.87300307\n",
            "  -2.3336658  -1.554365    1.7374347  -2.6428702 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mZTEUoCbuQM3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Redefining CausalConv1D to simplify its return values\n",
        "class CausalConv1D(tf.layers.Conv1D):\n",
        "    def __init__(self, filters,\n",
        "               kernel_size,\n",
        "               strides=1,\n",
        "               dilation_rate=1,\n",
        "               activation=None,\n",
        "               use_bias=True,\n",
        "               kernel_initializer=None,\n",
        "               bias_initializer=tf.zeros_initializer(),\n",
        "               kernel_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               trainable=True,\n",
        "               name=None,\n",
        "               **kwargs):\n",
        "        super(CausalConv1D, self).__init__(\n",
        "            filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            strides=strides,\n",
        "            padding='valid',\n",
        "            data_format='channels_last',\n",
        "            dilation_rate=dilation_rate,\n",
        "            activation=activation,\n",
        "            use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer,\n",
        "            bias_initializer=bias_initializer,\n",
        "            kernel_regularizer=kernel_regularizer,\n",
        "            bias_regularizer=bias_regularizer,\n",
        "            activity_regularizer=activity_regularizer,\n",
        "            kernel_constraint=kernel_constraint,\n",
        "            bias_constraint=bias_constraint,\n",
        "            trainable=trainable,\n",
        "            name=name, **kwargs\n",
        "        )\n",
        "       \n",
        "    def call(self, inputs):\n",
        "        padding = (self.kernel_size[0] - 1) * self.dilation_rate[0]\n",
        "        inputs = tf.pad(inputs, tf.constant([(0, 0,), (1, 0), (0, 0)]) * padding)\n",
        "        return super(CausalConv1D, self).call(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4zh6aM9uWVP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TemporalBlock(tf.layers.Layer):\n",
        "    def __init__(self, n_outputs, kernel_size, strides, dilation_rate, dropout=0.2, \n",
        "                 trainable=True, name=None, dtype=None, \n",
        "                 activity_regularizer=None, **kwargs):\n",
        "        super(TemporalBlock, self).__init__(\n",
        "            trainable=trainable, dtype=dtype,\n",
        "            activity_regularizer=activity_regularizer,\n",
        "            name=name, **kwargs\n",
        "        )        \n",
        "        self.dropout = dropout\n",
        "        self.n_outputs = n_outputs\n",
        "        self.conv1 = CausalConv1D(\n",
        "            n_outputs, kernel_size, strides=strides, \n",
        "            dilation_rate=dilation_rate, activation=tf.nn.relu, \n",
        "            name=\"conv1\")\n",
        "        self.conv2 = CausalConv1D(\n",
        "            n_outputs, kernel_size, strides=strides, \n",
        "            dilation_rate=dilation_rate, activation=tf.nn.relu, \n",
        "            name=\"conv2\")\n",
        "        self.down_sample = None\n",
        "\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        channel_dim = 2\n",
        "        self.dropout1 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
        "        self.dropout2 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
        "        if input_shape[channel_dim] != self.n_outputs:\n",
        "            # self.down_sample = tf.layers.Conv1D(\n",
        "            #     self.n_outputs, kernel_size=1, \n",
        "            #     activation=None, data_format=\"channels_last\", padding=\"valid\")\n",
        "            self.down_sample = tf.layers.Dense(self.n_outputs, activation=None)\n",
        "        self.built = True\n",
        "    \n",
        "    def call(self, inputs, training=True):\n",
        "        x = self.conv1(inputs)\n",
        "        x = tf.contrib.layers.layer_norm(x)\n",
        "        x = self.dropout1(x, training=training)\n",
        "        x = self.conv2(x)\n",
        "        x = tf.contrib.layers.layer_norm(x)\n",
        "        x = self.dropout2(x, training=training)\n",
        "        if self.down_sample is not None:\n",
        "            inputs = self.down_sample(inputs)\n",
        "        return tf.nn.relu(x + inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XSojTep1uZu7",
        "colab_type": "code",
        "outputId": "c619c283-b097-45bd-8ca4-aa33750ab0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Graph().as_default() as g:\n",
        "    x = tf.random_normal((32, 10, 4)) # (batch_size, length, channel)\n",
        "    tblock = TemporalBlock(8, 2, 1, 1)\n",
        "    output = tblock(x, training=tf.constant(True))\n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "with tf.Session(graph=g) as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    res = sess.run(output)\n",
        "    print(res.shape)   \n",
        "    print(res[0, :, 0])\n",
        "    print(res[1, :, 1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 10, 8)\n",
            "[0.        0.        0.        0.2258923 0.        0.        0.\n",
            " 0.        0.3263411 3.5823278]\n",
            "[0.         0.         0.         0.         4.0272355  0.\n",
            " 0.         0.         1.933734   0.35593283]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ku4X09jdutE0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TemporalConvNet(tf.layers.Layer):\n",
        "    def __init__(self, num_channels, kernel_size=2, dropout=0.2,\n",
        "                 trainable=True, name=None, dtype=None, \n",
        "                 activity_regularizer=None, **kwargs):\n",
        "        super(TemporalConvNet, self).__init__(\n",
        "            trainable=trainable, dtype=dtype,\n",
        "            activity_regularizer=activity_regularizer,\n",
        "            name=name, **kwargs\n",
        "        )\n",
        "        self.layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            out_channels = num_channels[i]\n",
        "            self.layers.append(\n",
        "                TemporalBlock(out_channels, kernel_size, strides=1, dilation_rate=dilation_size,\n",
        "                              dropout=dropout, name=\"tblock_{}\".format(i))\n",
        "            )\n",
        "    \n",
        "    def call(self, inputs, training=True):\n",
        "        outputs = inputs\n",
        "        for layer in self.layers:\n",
        "            outputs = layer(outputs, training=training)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F56usWVzu141",
        "colab_type": "code",
        "outputId": "d24b8d75-cb47-4b6d-b67b-662888b1b7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Graph().as_default() as g:\n",
        "    x = tf.random_normal((32, 10, 4)) # (batch_size, length, channel)\n",
        "    tcn = TemporalConvNet([8, 8, 8, 8], 2, 0.25)\n",
        "    output = tcn(x, training=tf.constant(True))\n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "with tf.Session(graph=g) as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    res = sess.run(output)\n",
        "    print(res.shape)   \n",
        "    print(res[0, :, 0])\n",
        "    print(res[1, :, 1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 10, 8)\n",
            "[ 0.1667993   0.754282    0.          0.32326317  0.66547775  1.4692276\n",
            "  0.          2.2628198   0.6556042  12.017203  ]\n",
            "[0.        0.        0.        1.5356847 0.        0.        0.\n",
            " 0.        0.        0.       ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YzEAivCfu5h8",
        "colab_type": "code",
        "outputId": "36909b4a-1eec-456c-9eb3-8edf3d02d2d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "    Xinput = tf.placeholder(tf.float32, shape=[None, 10, 4])\n",
        "    tcn = TemporalConvNet([8, 8, 8, 8], 2, 0.25)\n",
        "    output = tcn(Xinput, training=tf.constant(True))\n",
        "    print(tcn.layers[0].down_sample)    \n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "with tf.Session(graph=g) as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    res = sess.run(output, {Xinput: np.random.randn(32, 10, 4)})\n",
        "    print(res.shape)   \n",
        "    print(res[0, :, 0])\n",
        "    print(res[1, :, 1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.layers.core.Dense object at 0x7f874173bba8>\n",
            "(32, 10, 8)\n",
            "[0.        0.        0.        8.308353  0.        1.1927321 0.\n",
            " 7.328927  6.311587  0.       ]\n",
            "[0.         1.2304927  0.         1.2514353  0.         8.906823\n",
            " 0.         0.9208402  0.28090048 1.5971172 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pLUQl4jQu9F9",
        "colab_type": "code",
        "outputId": "f5fa4fb5-098a-4563-bada-60fbcf805991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "display_step = 500\n",
        "total_batch = int(5435 / batch_size)\n",
        "print(\"Number of batches per epoch:\", total_batch)\n",
        "training_steps = 2000\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 40 \n",
        "timesteps = 1 # timesteps\n",
        "num_classes = 10 #  total classes (0-9 digits)\n",
        "dropout = 0.1\n",
        "kernel_size = 8\n",
        "levels = 6\n",
        "nhid = 20 # hidden layer num of features"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of batches per epoch: 169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GK3Mb9vBvdD4",
        "colab_type": "code",
        "outputId": "a88d3136-f63b-421f-8375-0b75069f3ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "    tf.set_random_seed(10)\n",
        "    # tf Graph input\n",
        "    X = tf.placeholder(\"float\", [None, num_input, timesteps])\n",
        "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
        "    is_training = tf.placeholder(\"bool\")\n",
        "    \n",
        "    # Define weights\n",
        "    logits = tf.layers.dense(\n",
        "        TemporalConvNet([nhid] * levels, kernel_size, dropout)(\n",
        "            X, training=is_training)[:, -1, :],\n",
        "        num_classes, activation=None, \n",
        "        kernel_initializer=tf.orthogonal_initializer()\n",
        "    )\n",
        "    prediction = tf.nn.softmax(logits)\n",
        "   \n",
        "    # Define loss and optimizer\n",
        "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "        logits=logits, labels=Y))\n",
        "    \n",
        "    with tf.name_scope(\"optimizer\"):\n",
        "        # optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "        # gvs = optimizer.compute_gradients(loss_op)\n",
        "        # for grad, var in gvs:\n",
        "        #     if grad is None:\n",
        "        #         print(var)\n",
        "        # capped_gvs = [(tf.clip_by_value(grad, -.5, .5), var) for grad, var in gvs]\n",
        "        # train_op = optimizer.apply_gradients(capped_gvs)    \n",
        "        train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "    # Evaluate model (with test logits, for dropout to be disabled)\n",
        "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    # Initialize the variables (i.e. assign their default value)\n",
        "    init = tf.global_variables_initializer()\n",
        "    saver = tf.train.Saver()\n",
        "    print(\"All parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.global_variables()]))\n",
        "    print(\"Trainable parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.trainable_variables()]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All parameters: 108992.0\n",
            "Trainable parameters: 36330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "geZMK_Fzvk25",
        "colab_type": "code",
        "outputId": "d5ce457b-433f-4c5a-d369-1d65d5108ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = False\n",
        "best_val_acc = 0.8\n",
        "with tf.Session(graph=graph, config=config) as sess:\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "    for step in range(1, training_steps+1):\n",
        "        \n",
        "        offset = (step * batch_size) % (train_y.shape[0] - batch_size)\n",
        "        batch_x = train_x[offset:(offset + batch_size)]\n",
        "        batch_y = train_y[offset:(offset + batch_size), :]\n",
        "        \n",
        "        \n",
        "        \n",
        "         \n",
        "           \n",
        "          \n",
        "         \n",
        "       \n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, is_training: True})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={\n",
        "                X: batch_x, Y: batch_y, is_training: False})\n",
        "            \n",
        "            print (\"Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.5f}\".format(acc))\n",
        "\n",
        "\n",
        "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
        "    print(\"Model saved in path: %s\" % save_path)\n",
        "    print(\"Optimization Finished!\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 1, Minibatch Loss= 2.280263, Training Accuracy= 0.15625\n",
            "Iter 500, Minibatch Loss= 1.545001, Training Accuracy= 0.53125\n",
            "Iter 1000, Minibatch Loss= 0.879534, Training Accuracy= 0.75000\n",
            "Iter 1500, Minibatch Loss= 0.923773, Training Accuracy= 0.68750\n",
            "Iter 2000, Minibatch Loss= 0.234974, Training Accuracy= 0.96875\n",
            "Model saved in path: /tmp/model.ckpt\n",
            "Optimization Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h4YGhAZnxVmV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "55VhDtkdAdbH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lt4PC7haC7f0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}